#OPENAI, GROQ, CLAUD
MODEL_API_KEY='your_api_key_here'

# Cache Configuration
# How long to keep cached responses (in seconds)
CACHE_DURATION=3600

# Whether to enable response caching
CACHE_ENABLED=true

# Agent Configuration
# Which OpenAI model to use for the agent
AGENT_MODEL='groq/llama-3.3-70b-versatile '

# Controls randomness in responses (0.0 = deterministic, 1.0 = creative)
AGENT_TEMPERATURE=0.7 